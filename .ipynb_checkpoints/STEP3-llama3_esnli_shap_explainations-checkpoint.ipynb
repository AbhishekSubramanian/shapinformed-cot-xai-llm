{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zrxesWU_B3EG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import gc\n",
    "import ast # To parse the string representation of the list/tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StM1RoG6B34F",
    "outputId": "d3155f0f-71dc-466c-e760-7f6a5ea65c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking/Loading model and tokenizer...\n",
      "Loading model and tokenizer...\n",
      "Model and tokenizer loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "access_token = \"\"\n",
    "\n",
    "# Max tokens for the generated *SHAP-informed explanation*\n",
    "max_shap_explanation_length = 100 # Might need more tokens for this\n",
    "# Input file path (output from the previous step)\n",
    "input_file_with_explanations = '/content/results_correct_with_explanations.csv'\n",
    "# Output file path\n",
    "output_file_with_shap_explanations = 'results_correct_with_shap_explanations.csv'\n",
    "# Number of top SHAP tokens to include in the prompt\n",
    "top_n_shap_tokens = 10\n",
    "\n",
    "# --- Original Label Mapping (Crucial for interpreting SHAP values) ---\n",
    "label_map = {\n",
    "    0: 'entailment',\n",
    "    1: 'neutral',\n",
    "    2: 'contradiction'\n",
    "}\n",
    "# Create inverse map: label name -> index\n",
    "label_to_index = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# --- Load Model and Tokenizer (if not already loaded) ---\n",
    "# Re-use the loading code from the previous script if needed,\n",
    "# ensuring the same configuration (dtype, device_map, pad_token).\n",
    "# Example minimal reload:\n",
    "print(\"Checking/Loading model and tokenizer...\")\n",
    "try:\n",
    "    model\n",
    "    tokenizer\n",
    "    print(\"Model and tokenizer already loaded.\")\n",
    "    model.eval() # Ensure it's in eval mode\n",
    "except NameError:\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"left\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        token=access_token,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    model.eval()\n",
    "    print(\"Model and tokenizer loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z-KRvtI1B3z8"
   },
   "outputs": [],
   "source": [
    "# --- Helper Function for Generation (Use the improved one) ---\n",
    "def generate_model_explanation(prompt, max_new_tokens):\n",
    "    \"\"\"Generates text using the loaded model (incorporate sampling/penalty).\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=tokenizer.model_max_length - max_new_tokens).to(model.device)\n",
    "    attention_mask = inputs.attention_mask\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id, # Important for stopping\n",
    "            # --- Use Improved Generation Params ---\n",
    "            do_sample=True,\n",
    "            temperature=0.7, # Or your preferred value\n",
    "            top_k=50,        # Or your preferred value\n",
    "            repetition_penalty=1.15 # Or your preferred value\n",
    "            # --- End Improved Params ---\n",
    "        )\n",
    "\n",
    "    input_length = inputs.input_ids.shape[1]\n",
    "    generated_ids = outputs[0, input_length:]\n",
    "    explanation = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    explanation = explanation.strip()\n",
    "\n",
    "    del inputs, outputs\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xSYYJMQtB3wB"
   },
   "outputs": [],
   "source": [
    "# --- Helper Function to Process SHAP String ---\n",
    "def get_top_shap_tokens(shap_str, pred_label, label_to_index_map, top_n=10):\n",
    "    \"\"\"Parses SHAP string and returns top N tokens for the predicted label.\"\"\"\n",
    "    try:\n",
    "        # Safely parse the string representation\n",
    "        shap_data = ast.literal_eval(shap_str)\n",
    "    except (ValueError, SyntaxError, TypeError) as e:\n",
    "        print(f\"Warning: Could not parse SHAP string: {e}\\nString: {shap_str[:100]}...\")\n",
    "        return \"Error parsing SHAP\" # Return placeholder on error\n",
    "\n",
    "    if not isinstance(shap_data, list) or not shap_data:\n",
    "        return \"No SHAP data\"\n",
    "\n",
    "    try:\n",
    "        # Get the index corresponding to the predicted label\n",
    "        pred_index = label_to_index_map.get(pred_label)\n",
    "        if pred_index is None:\n",
    "            print(f\"Warning: Predicted label '{pred_label}' not found in label_to_index map.\")\n",
    "            return \"Unknown label index\"\n",
    "\n",
    "        # Calculate importance score (absolute SHAP value for the predicted class)\n",
    "        token_importance = []\n",
    "        for item in shap_data:\n",
    "             # Ensure item is a tuple/list with at least two elements (token, values_list)\n",
    "            if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                token = item[0]\n",
    "                values = item[1]\n",
    "                 # Ensure values is a list/tuple and index is valid\n",
    "                if isinstance(values, (list, tuple)) and len(values) > pred_index:\n",
    "                    # Use abs value of SHAP for the predicted class as importance\n",
    "                    importance = abs(values[pred_index])\n",
    "                    token_importance.append((token, importance))\n",
    "                else:\n",
    "                    # Handle cases where values format is unexpected\n",
    "                    # print(f\"Warning: Unexpected SHAP values format for token '{token}': {values}\")\n",
    "                    pass # Optionally skip or assign default importance\n",
    "            else:\n",
    "                # Handle cases where item format is unexpected\n",
    "                # print(f\"Warning: Unexpected item format in SHAP data: {item}\")\n",
    "                pass # Optionally skip\n",
    "\n",
    "\n",
    "        # Sort by importance (descending)\n",
    "        token_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Get top N tokens (the actual token strings)\n",
    "        top_tokens = [item[0] for item in token_importance[:top_n]]\n",
    "\n",
    "        # Return as a comma-separated string for the prompt\n",
    "        return \", \".join(top_tokens)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing SHAP data for label '{pred_label}': {e}\")\n",
    "        return \"Error processing SHAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPwDolnWB3sv",
    "outputId": "270b5e14-1bd4-4018-d53f-7c083c496515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results from /content/results_correct_with_explanations.csv...\n",
      "Loaded 179 samples.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Data ---\n",
    "print(f\"Loading results from {input_file_with_explanations}...\")\n",
    "try:\n",
    "    df_correct = pd.read_csv(input_file_with_explanations)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {input_file_with_explanations}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Ensure 'shap_value' column exists\n",
    "if 'shap_value' not in df_correct.columns:\n",
    "    print(f\"Error: 'shap_value' column not found in {input_file_with_explanations}.\")\n",
    "    exit()\n",
    "# Ensure 'pred_label' column exists\n",
    "if 'pred_label' not in df_correct.columns:\n",
    "     print(f\"Error: 'pred_label' column not found in {input_file_with_explanations}.\")\n",
    "     exit()\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(df_correct)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a953b75652e248239805bd568b8c172c",
      "3badfe856b9b46b598d99d82a46a2bb8",
      "77a080e2a6d647ee8e42e60a09f0b82f",
      "32837e9dda6f4965b0690b1ccdf6d698",
      "e99da6035d61497bb9f4a3a05ee712e0",
      "6b206934466b4162bcaf498c8c227edf",
      "f17670119ae54e4897d09c7158582213",
      "6ce44ce827b84ae9a08c4947ee8f3d7c",
      "b5a4784195cb4c778c98d3b1c6c38a09",
      "71076a2180524777b4b9fedf0a44d736",
      "f6131881749f46a9bc637e46a92062e3"
     ]
    },
    "id": "w4ZdBn5pB3pt",
    "outputId": "144c9ac4-9f3b-491c-e5a0-fa2c9fd4eeaa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating SHAP-informed explanations (top 10 tokens, max_new_tokens=100)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a953b75652e248239805bd568b8c172c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating SHAP Explanations:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both of them hold two packages.\n",
      "A person who is washed his or her hand has done something to prevent illness.\n",
      ",  One,\n",
      "        classifies it into entailments: Washed Hand\n",
      "1. ,  , .       ;    4;     ,     ;    6;\n",
      "5.  7.          ;\n",
      "8.        ,\n",
      "9.          ,   \n",
      "10.             0-3\n",
      "11.                -4\n",
      "12.                   -\n",
      "13.                    +\n",
      "14.                    !\n",
      "15.\n",
      "(1) It is possible that the text refers not only to an actual person but also to someone else. This would mean that it cannot be determined whether the subject is actually present at the location or just referred to by name. In addition, since there are many ways to refer to people in English, even if one could determine who is being talked about, how would one know which way the speaker means? For example, instead of referring to \"a girl\", we might use the pronoun she\n",
      "Boys played in a way that they were not protected from injuries.\n",
      "A token is likely to be selected if it's in a part of speech that has a lot of positive examples.\n",
      "            This hypothesis is not supported because some example sentences with bowl don't have any other tokens from uniform or helmet.\n",
      "This hypothesis states that \"a man in a blue shirt\" entails a car. To support our premise, we must demonstrate that every time an agent sees a person in a certain color (blue) they will perceive them to be driving around on a car.\n",
      "1    0       0      4     2     3     5\n",
      "2    8       6      7     9    11    13\n",
      "3   15      12\n",
      "In order to identify whether or not the man is wearing a white t-shirt.\n",
      "Prop has a higher degree than Child in the hypothesis.\n",
      "    <rdf:RDF xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:bibo=\"http://purl.org/ontology/bibo/\" xmlns:dspace=\"http://digital-repositories.org/ontologies/dspace/0.1.0#\" xmlns:scholar=\"http://schema.org/\"\n",
      "Child reached his hand towards the propeller. Model found that it's not\n",
      ".\n",
      "We can see that each of those words has its own definition (and so are not all synonyms), which explains the contradictions.\n",
      "Model's rule base contains no information about falling. Thus it would be impossible to make such a prediction from the premise.\n",
      "This paper presents an analysis of natural language understanding (NLU) systems which use statistical models. It focuses on two classes of NLU systems that employ machine learning techniques to solve problems with text: content-based question answering and knowledge discovery from textual data. We present results from three different experiments aimed at analyzing how well state-of-the-art machine-learning algorithms can handle these tasks. These include\n",
      "This is an entailment because it is based upon common knowledge. It also uses two premises that relate to each other (People ride bikes; people compete) which implies that they must both be true.\n",
      "Model Identification\n",
      "If the hypothesis is true then there will be a sentence where the subject is not \"boy\" but instead it's \"young\".\n",
      "This is one of several possible classifications.\n",
      "This is because they were most likely to be present on sentences that had been rated as very important by the annotators.\n",
      ".\n",
      "In order to make its decision about whether or not\n",
      "        a token is entailment (i.e. that it entails some proposition),the classifier first looked at all words\n",
      "        which are part of the premise.\n",
      "        If one of those words is also present in the hypothesis,\n",
      "         then the hypothesis qualifies itself as being an entailment of the premise by definition.\n",
      "        Otherwise if there's no such word in either the hypothesis nor the premise, then the\n",
      "         hypothesis isn't entailed by\n",
      "These words were most likely to be found in neutral contexts.\n",
      "    [1.5] : 0.0000099\n",
      "There were two people present. One of them had on a long robe that looked like it would be worn by someone who has just come out from a temple or something.\n",
      "This hypothesis is based on evidence of similar events that have been previously observed at other festivals. It can be inferred from the data that it will probably happen again.\n",
      "        Based on analysis of the original dataset, we are confident that the sample selected by our algorithm is representative of the population of interest (e.g., people who attend events with large crowds). In particular, the majority of the records in the training set were related to large-scale events like concerts or sporting matches, rather than smaller gatherings such\n",
      "(model used semantic role labels instead of syntactic roles.)\n",
      "        The model predicted that there were two entities in the sentence.: \"A man walks into a bar.\" It found that the subject,\n",
      "        direct object and indirect object are all part of the same entity. In addition it recognized that \"into\" and \"bar\"\n",
      "        both modify a single argument.\n",
      "    <record type=\"http://www.w3.org/ns/prov#Action\"><rdf:type rdf:resource=\"http://purl.ob\n",
      "We hypothesize that relaxing after a long day of work will make people happier. People are more likely to take part in recreational activities when they feel relaxed.\n",
      "1)   While doing laundry can be considered an entailment. However, if someone were to laugh at me while I'm in my house with no one around (such as when I'm doing something like folding clothes), then they would not have any reason or intent to do so.\n",
      "2)  If you are laughing, you are happy, which does not mean anything about what's going on in your life at the moment. For example, maybe you're just being silly and joking around during\n",
      "Dry = (dry|is) + He = (he|finds)\n",
      "As it is clear from my previous hypothesis that both\n",
      "Inferences were drawn from context to make predictions about which words would be considered relevant in order to make decisions. This is done by looking at the word frequencies within each document (in our case, tweets) and comparing them with those found across all other documents. If there are more frequent occurrences of certain words compared to others then we assume that they will occur together.\n",
      "We can't just assume it's right because we've never seen it before. So to confirm our hypothesis, I will look at some examples of where we have actually been driving in opposite directions.\n",
      "This sentence is from Wikipedia's article on \"Urban development\". It provides two instances of our hypothesis. If we were looking at another source like the New York Times or Time magazine, then we would probably not expect to find such evidence.\n",
      "    We need more information about what the context is like here. For example, could you provide some examples of sentences that contain both an SUV and a man? Do they often occur together? Can you give any reason why one might be expected there?\n",
      "This is because it had more positive examples of taxis driving around than negative ones. It also has more instances where there are no negatives (i.e., only positive) than that of negatives.\n",
      "    \"type\": \"Document\",\n",
      "      \"@context\" : {\n",
      "            \"schema\":\"https://schema.org\"\n",
      "              \"about\" : { \"$ref\" : \"#/definitions/taxi_suv\" },\n",
      "                \"name\" : \"taxi_suv\"\n",
      "          \"@id\" : \"/model/categorical\n",
      "This classifies the text into two categories. One category contains words which describe a girl performing an act of showing off or being proud (e.g., \"is\", \"show\", etc.). Another one has no relation to the topic.\n",
      "        What other information could have been used? If you were evaluating whether there are any differences with respect to the label given by each token, what would be your criteria?\n",
      "        How did the model classify different texts that had similar meaning but differed from each other according to\n",
      "This sentence explains what makes it so difficult to identify entailments in this scenario.\n",
      "No explanation is needed.\n",
      "The premise in question contains no negative polarity items. For instance there are no negated verbs (the word \"not\" cannot be used before a verb) nor any adverbs like \"very\". This makes it hard to understand whether or not the subject should take an affirmative form.\n",
      "       <Relation> entailment </Relation>\n",
      "     <RelConStr> The relation entails </RelConStr>\n",
      "         <RoleRef> http://www.w3.org/2006/03/prediction#pre\n",
      "These two words are used in similar contexts. They were both associated with children's toys.\n",
      "        This analysis has been verified by humans.\n",
      "These are all pronouns. In English, pronouns have an optional antecedent that allows them to be used in place of nouns.\n",
      "This classifying rule had the highest support value.\n",
      "I have never been in a situation like that before so it is hard to know what they are talking about. But she did seem confused.\n",
      "because it's not just about picking cereals. It has to do with where he wants to put them.\n",
      "[A] because she is weaing it. It could be that she has woven clothes before.\n",
      "            --->> Not relevant to hypothesis <---\n",
      "[None]\n",
      "This is because they are more likely to have been used in an entailment than other words.\n",
      "For example, when it came up in\n",
      "                            conversation with another participant. \n",
      "\n",
      "        Show how you would use this classifier in an application of natural language processing.\n",
      "        \n",
      "    -0.00000000e+00      1.33383333e-12     3.66666767e-07         2.1666667       5.8888899    \n",
      "    +0.00000000e+00          NaN              4.99999498e-\n",
      "This sentence makes it clear that both an individual \n",
      "and a place can be present at once. Therefore, we chose to classify this sentence as \"both\".\n",
      "<e.g.> \"It's not that they don't understand what I'm saying,\n",
      "        but because their attention is focused on something else\"\n",
      "1. The hypothesis states that children are more likely to look at bicycles when there are other things going on around them.\n",
      "2. This does not mean that all people will automatically take their eyes off of bicycles just because others have done so first.\n",
      "3. It doesn't matter if children are actually paying attention or not; it only matters whether the context\n",
      ".\n",
      "    \"http://dbpedia.org/resource/California\"\n",
      "    \"http://dbpedia.org/resource/San_Luis_Obligado_State_Park\"\n",
      "    \"http://dbpedia.org/resource/Mexico_City\"\n",
      "    \"http://dbpedia.org/resource/Cerritos_Grove_Senior_Community\"\n",
      "    \"http://dbpedia.org/resource/Pueblo_Nuevo_La_Mesa\"\n",
      "    \"http://dbpedia.org/resource/Tijuana\"\n",
      "    \"http://dbpedia\n",
      "This hypothesis is about a small set of words that occur in relation to \"outside\". These are relatively frequent words when used with other sets. I feel confident in my ability to identify these words because they have been seen before.\n",
      "This analysis will be useful for determining if there is some kind of statistical bias on our side or if we can generalize this technique to new data.\n",
      "For example, if you're going out to eat somewhere and your date asks where the bathroom is then it makes sense to say something\n",
      "We considered that there were three kinds of objects in the input.  Firstly we had a collection of words from which we could identify specific nouns such as \"hot\" or \"balloon\".  Secondly, we have an array of values to represent numbers like 5 or 2.3. Finally we can use punctuation marks (.) to separate individual words.\n",
      "        The dataset contains only one class - all other classes would be ignored by our classifier.\n",
      "        When comparing the two models' performance with\n",
      "In order to make my hypothesis work I need to know if men stood at least one step away from\n",
      "        any object in the scene. If they did not then it would be impossible to determine whether or not that man is holding something.\n",
      "Music is very important in our lives.\n",
      "This sentence has a strong entailment relation with the hypothesis. (This can be seen from both sides of the table.)\n",
      "         For all sentences x, if   then.    \n",
      "      <sentence> = {<sent1>,..., <sentn>}  \n",
      "      : Sentence x entails y iff there exists an integer k such that :\n",
      "            ((x == <sentk>) or (<sentk-1> <= x) or (y!= <sentk+1>))\n",
      "    In other words,\n",
      "This is just one instance where color had no effect.\n",
      "This is an entailment example. We are interested in classifying whether or not the premise is entailed by the hypothesis.\n",
      "        In this case we see that it has been decided to classify all of them as true because they match up perfectly with what was expected from our hypothesis.\n",
      "This example contains two potential examples of dogs.\n",
      "This hypothesis could be tested by testing whether or not other words were also relevant. For example, \"a man\" would make an interesting test case because it may indicate that the speaker's intention of using the word \"man\" in her question should be taken into account.\n",
      "This model used an SVM classifier to classify the three boys into two classes. Since it did not have any training data with class labels associated with each image (i.e., no positive or negative examples), we decided that our goal in using this model would be to detect neutral images by finding those instances where at least half of the objects in the picture were yellow.\n",
      "; and ,   ;and,\n",
      "         .    ;was predicted as \"negative\" because none of the characters wore a yellow shirt,\n",
      "The presence of the word \"camera\" in front of other words influenced it to classify this image as an entailment.\n",
      "    <DOCID:#20030610>\n",
      "A token with an unusual meaning is more likely to be used in a contradiction than other tokens.\n",
      "This information indicates that the premise mentions a street performance by an individual wearing a bowler hat. A similar scenario could be expressed using other lexical items such as \"person\" or \"street performer\".\n",
      "It identifies all instances of \"grass\", \"child\" and \"young\" boys. These are then compared to an annotated dataset containing only children (in the grass) which yields five positive results.\n",
      "because it saw that there are two players who have different colors of jerseys.\n",
      "This is an example of a contradiction. According to our hypothesis, we expect that there will be two participants in this scene (the person who throws the tomato and the one being hit). However, according to the data, it appears that only one participant has been named.\n",
      "This class is only used in one sentence (the first line), so we can assume that it's not very important.\n",
      "Because \"standing\" is closer to word order than \"is entailed by\", it will be more probable that people standing in line are considered together with other information about them.\n",
      "There were many possible explanations. First, it may be that people who are drinking beers at the time are more likely to stand in lines because they're enjoying their drinks. Second, there is also the possibility that those who don't have food with them aren't standing in line since most of us know what we want when eating so we can get straight into our food without having to wait around. Thirdly, people who are hungry will often choose to eat before sitting down for dinner (which means they\n",
      "Because of its relation to \"Hypothesis\"\n",
      "[0]   \"the premise is about finances.\"\n",
      "    [1]   \"they're discussing how they'll be able to afford it.\"\n",
      "There were three possible ways that the phrase could be used. One way is to refer to a person who stands in front of an ice-cream van (i.e., \"A man is selling ice creams\"), which seems likely given the context.\n",
      "        Determine if you can explain your reasoning using only information provided by the data: Not really necessary here because we already know what happens when one or more of those things occur.\n",
      "        Write down any additional facts about entailments not covered above:\n",
      "            .\n",
      "Because we have a hypothesis about what is likely to occur after one person buys an ice cream cone. We use that information (the premise) to make our prediction.\n",
      "Because of its high probability.\n",
      "These words were often found in sentences that contained either or both hypotheses. For example, a sentence such as \"the two cooks\" would include the premise while also containing one hypothesis.\n",
      "\n",
      "This sentence seems to contain a word that indicates the topic of the paragraph (the \"desert\"), but also contains words which indicate the speaker's personal experience (wandering). I think it is likely that some sort of connection exists between these two ideas.\n",
      "This is because of its context with \"A thesis\".\n",
      "        Add to list or move up/down on the results page:\n",
      "    | word         | weight |\n",
      "    --------------------------------------------------------------------\n",
      "    |.           |     -0.1 |\n",
      "    | ese          |      5 |\n",
      "    | ae            |       4 |\n",
      "    | i             |       3 |\n",
      "    | n               |       2 |\n",
      "    | t              |       1 |\n",
      "    | e             |       1 |\n",
      "1) no relation; 2) relation but not strong enough.\n",
      "        The following factors were considered by the model:\n",
      "                class (class label): 0.97;\n",
      "            subject: [bright], [orange] ;\n",
      "            object: [woman];\n",
      "            predicate: [walks];\n",
      "            relation: none\n",
      "Note that it may be necessary to revise some of the labels before training on data from new domains or new languages.\n",
      "This example shows how we can use NLTK's tools to analyze\n",
      "[1] \"Premises\" in the context of natural language understanding are statements that state the conditions under which some action might occur. (http://www.speech.cs.cmu.edu/cgi-bin/courses/lcs/nlp-lab.html)\n",
      "       [2] \"Hypotheses\" are statements about the world or other people's thoughts that make claims about how things must be.\n",
      "           -   http://en.wikipedia.org/wiki/Hypothetical_essay\n",
      "This class had 4 instances.\n",
      "        Corrected tokenization (see https://www.kaggle.com/c/udacity-anomaly-detection/discussion/10858)\n",
      "There are many reasons that can lead us to classify one event or token more highly than another. Here we consider three main factors:\n",
      "            (1)   Entailment: We have been trained by our language acquisition process to see events like \"A man walks down the street\" as entailed; therefore if there is evidence suggesting that an event such as \"a man with a hand in his pocket walks down the street\" is also entailled then it would be reasonable to assume that this instance might\n",
      "This hypothesis states that there are three ways to reach the top of the ramp. One way is by jumping on it with your feet. Another way is to climb up using an edge or step. Finally, you can use a skateboard (i.e., a \"skateboarder\"). Thus, we hypothesize that all skaters are not necessarily wearing shoes.\n",
      "This hypothesis contains only one premise because each statement about skating has at least two possible conclusions:\n",
      "    * For example, if someone says they have\n",
      "I chose to classify this because it is contradictory. It seems like if you put them together they would be too confusing.\n",
      "        Provide further explanation of your rationale: This contradiction occurred by mistake, so we will have to work on finding other contradictions in our text that could cause us trouble later on down the line.\n",
      ".\n",
      "This hypothesis uses evidence from the premise that someone is helping to bathe the baby. It suggests that there may be more than one actor who might have helped with the bathing of the child.\n",
      "This sentence is about an old man enjoying himself in nature. In order to find out which of his hobbies he does not enjoy (which would make him unhappy), it seems logical that we need to check whether or not he likes walking around.\n",
      "A hypothesis can be tested by using data from another source to see if they agree with our prediction. Here, I use two examples:\n",
      "1) Data obtained from \"Mood Meter\" app on Google Play Store.\n",
      "    https://play.google.com/store/apps/details\n",
      "We have to consider that there are only three sentences from which we can make an inference. But if I say \"A middle- aged man sits in front of me,\" then it means he's not lying down or standing up.\n",
      "        Describe how you would change your approach to avoid making such mistakes in future: This should be obvious but one must always check whether the sentence is true by observing the context carefully before inferring anything about what happened.\n",
      ". These words were very likely to be used by players when deciding whether or not to kick a ball. They are also fairly frequent.\n",
      "        \n",
      "         - Classifiers that contain more than one word (such as 'the' and 'and') should only have their most common meaning included in the prediction; we will consider them \"negated\" predictions.\n",
      "\n",
      "        Identify two alternative explanations:.\n",
      "            * An example of an alternate explanation would include some context such as:\n",
      "\n",
      "                When I'm playing with my brother\n",
      "Artwork is an important part of the picture. It's one way to sell things.\n",
      "Artwork 3\n",
      "\n",
      "Inclusion of \"is\" token in hypothesis.\n",
      "(1) It has been trained to identify Asian men.\n",
      "(2) Model used \"mop\" in context with other words it had learned. For example, if you say that \"John has an interest in mops\", then your model should recognize that mopping can be part of John's interests.\n",
      "Model makes the classification by looking at both the token and its context.\n",
      "This information makes it clear that there are two possibilities:\n",
      "            If you have a white screen and project onto it, then your audience will be able to see what\n",
      "             you're doing. You can do something interesting with an overhead projection.\n",
      "           Or if you just put up some slides on the wall behind you, but don't use any technology,\n",
      "          such as a computer or projector, then nobody would know anything about how you got\n",
      "           those pictures together. In other words, when people look\n",
      "This classifies token 2 in sentence (1) because it describes an event that can be seen or heard. Token 3 is also described in some way but not necessarily seen or heard.\n",
      "        In what ways does the model make predictions? How well do they match reality?\n",
      "        Did you find any errors in the explanations of how the classifier arrived at its decisions? If so, explain them.\n",
      "         {A|B}       Match the hypothesis with one of the following:\n",
      "            B - Yes\n",
      "The premise contains the words \"man\" (a person) in its first clause. It also mentions a projection of light from an object on a screen.\n",
      "    \"\"\"\n",
      "    \n",
      "    return hypothesis\n",
      "It seemed to me that it would be good if we could say something about the clothes.\n",
      "This is a good fit because they are all nouns which refer to things that can be shot at. These also seem like appropriate words given the context in which it appears.\n",
      "     1 : A gun (noun)   => Guns\n",
      "     2 : A four-gun man's crew  => GUN crew\n",
      "     3 : Two guns or more    => Gun(s)\n",
      "         4 : One gun           => Gun\n",
      "Model used the premise to determine that there were at least two people on the street.\n",
      "* This sentence describes an object or action. It can be used to make a statement about that thing.\n",
      "            * Model provides evidence of what we want it to provide. In other words, you are using it to justify your claim (see our help pages).\n",
      "*This is how I would say it:\n",
      "    A black late-model station wagon is parked in the background.\n",
      "The following sentences were also considered but not selected by the annotator due to insufficient data:\n",
      "\n",
      "*,., *, :.,,\n",
      "\"A light black late model station wagon is in the background.\"\n",
      "These two sentences are about the same man. Therefore they share one common feature.\n",
      "In my opinion, it would be difficult to determine whether or not an entailment exists when using only one sentence. As I mentioned before, if you want to have greater certainty of what is being said, then use more than just one word.\n",
      "        If your hypothesis has been tested against multiple sentences, please state which ones were used; otherwise, explain how you determined that all sentences fit within the same category (e.g., \"This statement includes all three words\").\n",
      "        This experiment showed that there are\n",
      "This classifies an instance of the input token\n",
      "        to be a drum.\n",
      "This token indicates that we should be using our knowledge of music to make decisions.  We can therefore classify it by its musical context.\n",
      ". This hypothesis is based on the premise that all three of them were walking along side one another. Footwear, however, has not been seen to be an issue when it comes to travel so there may have just been some form of coincidence here.\n",
      "        Did any other factors influence your choice? Yes, I did consider the fact that they were all wearing similar outfits which could indicate that they might share common interests or hobbies. Additionally, if we assume that none of them had their phones with them then\n",
      "we use word embeddings (tf-idf) and tf-embeddings. This gives us better results than our baseline with only bag-of-word. Also, I think that in some cases it is more interesting to know whether they have expected something or not.\n",
      "        What if you did ngram instead of using token-level features?\n",
      "    '''\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "from keras.preprocessing.text import Tokenizer\n",
      "\n",
      "def load_data():\n",
      "    data = []\n",
      "\n",
      "    # Read training file into memory:\n",
      "    f =\n",
      "There is no reason to explain. This token has been correctly predicted by all other models.\n",
      "In order to make inference about entailment of the sentence \"A man in a black shirt is smiling at a woman\" we need to identify all the entities mentioned by this token. If there are two or more entity mentions it would not be possible to determine which one should go with that part of speech.\n",
      "In general, our data were not consistent enough in order to make predictions.\n",
      "    \"\"\"\n",
      "    hypothesis = [token[0] + token[1] + \"with\" + token[2:] for token in zip(\n",
      "            [\"coat\", \"scarf\"], [\"are\",\"have\"])]\n",
      "    \n",
      "    # Create lists of all hypotheses that match with each other:\n",
      "    matches_hypotheses = [[hypothesis.index(h) for h in i if len(set(i)) == 4]\n",
      "                         for\n",
      "There are three elephants in one group. They all have different colors.\n",
      "This hypothesis makes sense because of all the information that we have been given. We know who the actor is (a diver), where he's going to be in space (swimming) what type of water he's swimming through (turtles). If you are diving with turtles then they're most likely going to bite on your head or something like that.\n",
      "<model id=\"2\">     <class>1</class>\n",
      "      <token type=\"outside\" lemma=\"outside\"/> \n",
      "       </model>\n",
      "    <model id=\"3\">         <class>4</class>\n",
      "      <token type=\"Prem\" lemma=\"A man with a beard skateboarding and a boy with a blue and black backpack riding a green bike in the background.\" />     \n",
      "  \t<token type=\"yypo\" lemma=\"boy\"/>  \n",
      "      <token type\n",
      "We want to predict whether or not two little sisters will be happy after going on a water slide. Since we have no prior knowledge of how they are feeling before entering the slide, our best guess is that if one sister says \"I'm so excited!\" then her sibling's likely happiness must also be high. This hypothesis does not make any assumptions about which girl may say what.\n",
      "There are two possible ways to classify this sentence. One way would be to treat it like any other noun phrase; that is, identify its first word as the head of a noun phrase (i.e., cook). This method works because there is only one main clause in the text--the subject-verb-object construction of \"person\" followed by an object (\"cooking\"). The second option is more complicated because it requires us to look at several words together before we can decide which ones constitute a single\n",
      "This token indicates that we should\n",
      "This data set contains information about people's hobbies. We can classify them into categories of interests such as cars, sports, music etc., but we don't want to label them according to a predefined list of possible values. Therefore, there is no obvious way that the classifier could have decided which value it should assign.\n",
      "        In order to deal with situations like those above, machine learning algorithms need to be able to learn from examples (see Chapter 3). For example, if you were told \"I\n",
      "There is no obvious reason to reject the hypothesis. This is because of how many different things are being described in both sentences. In one sentence there is only \"a\" person who is holding something that is not what we know it's supposed to be (the paperbag). In another sentence there is also multiple people all looking at each other.\n",
      "Based on how they were defined in the corpus.\n",
      "This hypothesis states that a child will blow bubbles when they are bored. Bubbles can be used to express emotions (e.g., happy) or boredom.\n",
      "(1) Boy =. \n",
      "           . is boy (2)\n",
      "           ..yopo= boy \n",
      "               ....is  ,   .\n",
      "                       ...ye-yespo  \n",
      "                     .....boy    boi\n",
      "                   ......boyeroo    \n",
      "                       booeroy     \n",
      "                              orey         \n",
      "                            rey          \n",
      "                         ryo           \n",
      "            ...........\n",
      "This is an example of a word in context.\n",
      "These models were used to determine which three people are present. (3)\n",
      "        Inference from example: 1-2 : This premise does not include all possible examples.\n",
      "        Conjunctions:\n",
      "         - conjunction 1\n",
      "            \"One\" is also mentioned in other premises., but it's not very clear what the connection is.: One could be referring to someone else or something else. Could there possibly be more than one person named \"one\"? Is he just making sure that we have an\n",
      "In this case there were four distinct objects that were being observed. This would lead us to classify it into a set of hypothesis statements (since we can not tell which object has been burnt). Since all three people have their hands over their mouths at once, they could be holding something similar.\n",
      "Because it's obvious that they are all animals. This should be enough to make us think of them as dogs.\n",
      "    \"\"\"\n",
      "    \n",
      "    # TODO: Add code here to process your hypothesis\n",
      "\"The sentence has two subjects (the dog and\n",
      "        the animal) that are related by possession. The verb sleep indicates the action of one subject,\n",
      "        i.e., the dog, upon another object.\"\n",
      "Both of them are in a good mood.\n",
      "\"the sun set\", which has a different meaning than \"two boys stood\".\n",
      "            :sun,\n",
      "              :set\n",
      ".\n",
      ".  Festival is an event. This token suggests that there must be more than one such events happening right now.\n",
      "         Thesis : There may not be any festivals going on right now or it could mean they are all over the place.\n",
      "        In other words, the information provided by this hypothesis does not provide enough evidence to conclude whether festivals are being held across the country or not.\n",
      "   ,  festivals\n",
      "        Is the model making false assumptions? Yes, because we know from experience that festivals can happen\n",
      ".\n",
      "1. We have an example where \"there's\" modifies \"one\". Therefore we know that there must be more than one thing to modify here.\n",
      "          This supports our hypothesis because the premise says there is only ONE child (and not multiple ones) but there are two things mentioned (\"a trashcan\", and \"the foot\").\n",
      "              So I would say that the entailment relation holds true because the word \"There\" is used twice in the first part of the premises. In order for us\n",
      "Model makes an inference that some students in class have been playing a game involving trashcans. This is supported by evidence from the children who were not playing (e.g., those sitting near the trash can) but do not actually see any games being played.\n",
      "This information can be used to develop an action plan:\n",
      "Modeling with data helps us understand what we don't know about our world, so we can take actions based on evidence gathered from different sources such as observations or experiments.\n",
      "This is because the words were placed together to form phrases. Also there might be an inference that could have been drawn from the sentence structure itself (e.g., \"A man looked at his watch\" can mean many things)\n",
      "I think it's because the word \"the\" in the second sentence has to do with who or what you are talking about. In my opinion, it would be very confusing if we said \"is sleeping on his bed\", rather than saying he is asleep.\n",
      "This classifies words that have an obvious meaning in context (such as \"door\"), but also includes other examples such as \"there\" or \"of\". In order to determine whether something belongs with \"There\", we must look at all possible alternatives. For example, if someone were trying to figure out where a particular word might belong in a sentence like \"I don't know what's wrong with you,\" they would need to consider how it could fit into the rest of the phrase (\"What's wrong\n",
      "It is difficult to judge whether or not there's anything wrong with the way I'm writing my paper. Perhaps I could use some help? Or maybe it would be better if someone else wrote the first draft?\n",
      "The subject has a specific meaning in English. This may be useful to add more information about it.\n",
      "    [0] = \"pot\", [1] = \"side\", [2] = \"the\", [3] = \"sitting\", [4] = \"with\", [5] = \"man\", [6] = \"is\", [7] = \"is\"\n",
      "This sentence appears to be a paraphrase.\n",
      "         It's also possible that some other relation could have been used.\n",
      "This token was chosen because it is an instance of the same concept. It could have been any number of different concepts.\n",
      "The most important token is the word \"bench\". It has two possible antecedents (i.e., either \"Prem\" or \"A\"), but only occurs after \"down\", so it must be the correct class. In addition, there are no other tokens that have any similar meaning to \"bench\".\n",
      ", because it contains token which are most important in relation to hypothesis.\n",
      "This hypothesis could be seen to follow from the premise.\n",
      "I think they're just so tired of being inside. It must be awful to sit in your house all day with nothing to do.\n",
      "        To make sure my results were accurate, I checked them against other websites such as Google, Yahoo!, Bing etc... which resulted in similar findings to mine.\n",
      "        In order to improve their accuracy, I would like to get some more information about what people who use computers actually find when searching online.\n",
      "        For example, by getting feedback from users directly through questionnaires\n",
      "This model identifies a class of words that are most likely to appear together in the same utterance. In our case, we can see from the data that dinner and crew are very common near each other (the number of times they occur within one word pair is quite high), so it's easy to assume that when someone says \"I'm going out tonight,\" he will also say \"to eat at [a restaurant].\"\n",
      "        Given that entailing information about meals has been shown in previous research to\n",
      "The word \"man\" appears in the text at least once.\n",
      "This is because it uses more than one token to identify what's being described. It also includes some punctuation (the comma) which helps clarify that the two people involved aren't just talking about themselves.\n",
      "            {boy} and {girl}\n",
      "              {jackets} see through them.\n",
      "             The clothes they're wearing would make those windows look like something out of an advertisement.\n",
      "      What were your predictions?\n",
      "          I think you have done a good job on modeling entailments; however there could be\n",
      "This hypothesis is based on evidence that people who wear clothes are more likely than those who do not to be criminals.\n",
      "It was possible because it has been proven that,.,  is a type of relation which means that when there's an entailment (this one) then you can assume that all those things will be true. So if you have [..] or...\n",
      "This classifies the first token that appears in the premise.\n",
      "            In order to classify the sentence into its sub-sentence, we need to find which one is related to it. So we use an algorithm called \"subgraph matching\" [3] to match each node from the hypothesis (the words) with their respective nodes in the context. If there is any word in both sentences, they will be matched together. Then if those two matches are connected by edges on the graph, then you have\n",
      "This sentence is not in any other text that we have seen. There is no evidence suggesting it has previously been used.\n",
      "I think that it is not so difficult to find a common denominator among all the factors listed in my hypothesis. It's obvious that they're very important for making the right decisions like \"I don't know what she wants.\" For me there were two main elements of the problem: first one is the fact that we have a lot of different people who want to say something about her but without any kind of agreement or mutual understanding with each other. This leads us to confusion when trying to make sense out\n",
      "This is an example from another dataset. It has been filtered down to just English words (e.g., \"Don\" does not appear in it).\n",
      "These are some of the most common words used in the dataset. They're also among those that appear frequently enough to make them likely candidates for inclusion.\n",
      "        Identify any potential causes of bias introduced by a particular type of data or processing technique (e.g., language, genre, style): This is an English sentence, so it's not surprising that there will be more than one word per sentence; but perhaps it would have been better to use a shorter length to avoid having too many consecutive spaces.\n",
      "If a child runs up to her mother, she will say \"Excuse me\". She is excited about something. This makes it likely that an excited child passes by someone's parent.\n",
      "This is a case of entailment.\n",
      "This hypothesis is supported by all of the evidence. All of the context is in agreement with this hypothesis.\n",
      "            A dog herd will try very hard not only to keep an animal from escaping but also to bring it back into its pen or corral (dog's home).\n",
      "        In addition, if a cow tries to escape again, then you can be sure that the dog wants to stop them again!\n",
      "        Therefore we should choose the hypothesis \"the dog herd tried to catch the cow\".\n",
      "This hypothesis is supported. These two sentences can be interpreted in different ways (e.g., \"They walk by a flower pot\" vs. \"There's a garden next to them\") but they both refer to an object that exists somewhere.\n",
      "1     0      6     0    Garden               yes   Yes      .          .\n",
      "2     0      7     8    Next                 no    No        ,          and,\n",
      "3     4      9    12\n",
      "Pool could be used to infer that it's water. There can only be one hypothesis about what the man is doing, so I assume he must have entered into the water.\n",
      "    (1) {pool} : pool\n",
      "       ⇒ entailment(there)\n",
      "    (2) {a} : a person\n",
      "       ⇒ entailment(pool), entailment(in)\n",
      "    (3) {of} : of\n",
      "       ⇒ entailment(a), entailment(of), entailment(water)\n",
      "    (\n",
      "This classifies dogs into two categories based on their color. Black is used to describe dark colored animals while brown describes lighter ones.\n",
      "        Provide additional information that may have influenced your final choice:\n",
      "        When I first started out with my project, I did not know what kind of data would be necessary to create an algorithm or even how it works. It took me quite some time before I found out about different types of algorithms and other relevant stuff like datasets and models etc. But now everything seems to make\n",
      "It can be seen that there are many words associated with swimming such as jump. In addition, we see that the word \"vacation\" appears very often.\n",
      "        Model explains how it got those results:\n",
      "            There were two types of sentences that occurred more frequently than others which helped make our predictions on whether or not someone would jump into the water.: \n",
      "                * Sentences containing the preposition `in' (`I jumped in`)\n",
      "                * Sentences containing the noun `swim`(`We\n",
      "It's because of its context. I don't think that it can be explained by any other reason.\n",
      "There are two main factors that determine whether or not to classify an image as entailing. One factor is how likely it is that the premise can be true given the world (i.e., the probability of finding evidence supporting each part). Another factor is whether there's enough information present within the sentence itself to support the entailment. In this case we're looking at a picture of a person sliding down a slope with snow, so we know they probably did fall from their sleigh.\n",
      "\n",
      "\n",
      "This sentence describes an object that could be either a tree or a lawn. It's hard to tell from just one word if it will also include other objects such as bushes.\n",
      "\n",
      ".\n",
      "The token,ye, which occurs in two different sentences (in both cases with the same meaning) has been labelled by the algorithm. This means that the word can be used in many contexts.\n",
      "In order to get more information about each class of tokens, we performed an analysis of their frequency distribution.\n",
      "\n",
      "We first conducted a basic frequency distribution to identify whether there were any distributions which had very low or high values, and therefore might have caused errors during training.\n",
      "\n",
      "\n",
      "```python\n",
      "from collections import Counter\n",
      "\n",
      "#\n",
      "Model makes a hypothesis about how to classify words in text.\n",
      "The first token in our hypothesis ('There') had already been predicted by other models. The second token ('is') was also an expected word; it would have appeared without any need to predict its presence.\n",
      "The reason that there were more false positives than true negatives might be due to some bias on the part of one or both classifiers:\n",
      "    * The classifier for \"there\" may not take into account all possible locations where the phrase can appear (\"in front\", \"behind\") when looking at just\n",
      "The token \"is\" had an entailed value.\n",
      "This hypothesis is about a single player. Therefore, it makes sense to classify them together.\n",
      "The fact that she has muddy hands indicates that she must be a child; moreover,\n",
      "        we know from previous experience that children have dirty hands. Additionally, it's possible that she had just gotten out of the\n",
      "        bath. Finally, since we don't see any other toys or objects around, we can assume that she got some dirt on her face while play-\n",
      "        ing.\n",
      "There is some overlap of senses here. In particular,\n",
      "        there's an overlap with the following example (which also involves two people):.,  are  standing.\n",
      "It seems that it's more likely that she will be on her own than with a partner.\n",
      "        \n",
      "         (0.3) : {Prem} --> [Contradict]\n",
      "            Prem = [\"A\", \"a\"] & Thesis = {\"is\",\"in\"} & Lawn = {'I', \"se\"}\n",
      "                 |          |\n",
      "             Contradict = True\n",
      "\n",
      "         (0.2) : {Thesis} --> [Contradict]\n",
      "            Thesis = {\"is\"|\"in\"} &\n",
      ".\n",
      "This token represents a contradiction because it has two different meanings. It can refer to both the sleeping woman or the sleeping room.\n",
      "         {    \"word\": [       \"woman\",   \",    ,      \",\n",
      "                   ],       \"class\": [\"object\"],             \"relation\": []\n",
      "            {              \"token\": [],                  \"sentence\": \"\",                    },\n",
      "           <http://dbpedia.org/resource/Alabama> -<http://dbpedia.org/resource/Louisiana>\n",
      "           {               \"type\": \"\n",
      "This is an example of entailment.\n",
      "        Describe how you would use this data to train a classifier that can detect other\n",
      "        kinds of entailments?: We could try using it to classify all sentences containing \"the\"\n",
      "        as being about the same kind of thing (e.g. whether they describe a person or not)\n",
      "        because we know the answer from our knowledge base.\n",
      "This token appears frequently enough to be considered relevant.\n",
      "This sentence does not make sense. I am trying to describe an image but you are asking me to explain my thoughts on it.\n",
      "    <b>man</b>\n",
      "    <i>A</i>\n",
      "      in \n",
      "       in\n",
      "        the    bench\n",
      "The class label \"Prem\" is highly predictive. It contains more than half of all examples in our dataset.\n",
      "        Predicted labels are incorrect if there were many false positives (e.g., \"way\", \"heading\") or negatives (\"is\"). This might be due to two reasons:\n",
      "            - Model learned that the classes \"premise\" and \"hypothesis\" have similar structure. For example, both contain words like \"an\".\n",
      "                These models may produce negative predictions when they cannot distinguish them\n",
      "The semantic role of \"man\" in (1) implies that he has come to pay homage at the shrine. Thus, it can be inferred that there must have been an earlier state where the speaker had mentioned some other people who came to pay their respects at the same place.\n",
      "        Explain your answer: The context provided by the sentence suggests that we are talking about a particular individual rather than just any random person walking down the street. So far, no one else appears to have paid respect to the\n"
     ]
    }
   ],
   "source": [
    "# --- Generate SHAP-informed Explanations ---\n",
    "model_explanations_shap = []\n",
    "print(f\"Generating SHAP-informed explanations (top {top_n_shap_tokens} tokens, max_new_tokens={max_shap_explanation_length})...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for index, row in tqdm(df_correct.iterrows(), total=df_correct.shape[0], desc=\"Generating SHAP Explanations\"):\n",
    "    premise = row['premise']\n",
    "    hypothesis = row['hypothesis']\n",
    "    predicted_label = row['pred_label']\n",
    "    shap_str = row['shap_value']\n",
    "\n",
    "    # Get the most influential tokens based on SHAP for the predicted class\n",
    "    important_tokens_str = get_top_shap_tokens(shap_str, predicted_label, label_to_index, top_n=top_n_shap_tokens)\n",
    "\n",
    "    # Handle cases where SHAP processing failed\n",
    "    if \"Error\" in important_tokens_str or \"No SHAP data\" in important_tokens_str or \"Unknown label\" in important_tokens_str:\n",
    "        shap_explanation = f\"Could not generate SHAP explanation ({important_tokens_str}).\"\n",
    "        print(f\"Skipping SHAP explanation for index {index} due to SHAP processing issue: {important_tokens_str}\")\n",
    "    elif not important_tokens_str:\n",
    "         shap_explanation = \"Could not generate SHAP explanation (No important tokens found).\"\n",
    "         print(f\"Skipping SHAP explanation for index {index} due to no important tokens found.\")\n",
    "    else:\n",
    "        # Construct the new prompt including the important tokens\n",
    "        shap_prompt = f\"\"\"The relationship between the Premise: {premise}; and\n",
    "        Hypothesis: {hypothesis}; was classified as '{predicted_label}'.\n",
    "        The model identified these tokens as particularly influential for this decision: {important_tokens_str}\n",
    "        Explain why model made the classification:\"\"\"\n",
    "\n",
    "        # Generate the SHAP-informed explanation\n",
    "        shap_explanation = generate_model_explanation(shap_prompt, max_new_tokens=max_shap_explanation_length)\n",
    "\n",
    "    model_explanations_shap.append(shap_explanation)\n",
    "    print(shap_explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEPn3qAoCwgr",
    "outputId": "3f392620-b537-466e-cff9-d055f185dc02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished generating SHAP-informed explanations.\n",
      "Total time taken: 310.77 seconds\n"
     ]
    }
   ],
   "source": [
    "# --- Add Explanations to DataFrame ---\n",
    "df_correct['model_explanation_shap'] = model_explanations_shap\n",
    "print(\"\\nFinished generating SHAP-informed explanations.\")\n",
    "end_time = time.time()\n",
    "print(f\"Total time taken: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFebKMXmB3m_",
    "outputId": "8154cb1e-970e-4686-b9f6-adf8912d9730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving updated DataFrame to results_correct_with_shap_explanations.csv...\n",
      "DataFrame saved successfully.\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "# --- Save Updated DataFrame ---\n",
    "print(f\"\\nSaving updated DataFrame to {output_file_with_shap_explanations}...\")\n",
    "try:\n",
    "    df_correct.to_csv(output_file_with_shap_explanations, index=False)\n",
    "    print(\"DataFrame saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving CSV: {e}\")\n",
    "\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlbCA58OFoeb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "32837e9dda6f4965b0690b1ccdf6d698": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71076a2180524777b4b9fedf0a44d736",
      "placeholder": "​",
      "style": "IPY_MODEL_f6131881749f46a9bc637e46a92062e3",
      "value": " 179/179 [05:10&lt;00:00,  2.23s/it]"
     }
    },
    "3badfe856b9b46b598d99d82a46a2bb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b206934466b4162bcaf498c8c227edf",
      "placeholder": "​",
      "style": "IPY_MODEL_f17670119ae54e4897d09c7158582213",
      "value": "Generating SHAP Explanations: 100%"
     }
    },
    "6b206934466b4162bcaf498c8c227edf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ce44ce827b84ae9a08c4947ee8f3d7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71076a2180524777b4b9fedf0a44d736": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77a080e2a6d647ee8e42e60a09f0b82f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ce44ce827b84ae9a08c4947ee8f3d7c",
      "max": 179,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b5a4784195cb4c778c98d3b1c6c38a09",
      "value": 179
     }
    },
    "a953b75652e248239805bd568b8c172c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3badfe856b9b46b598d99d82a46a2bb8",
       "IPY_MODEL_77a080e2a6d647ee8e42e60a09f0b82f",
       "IPY_MODEL_32837e9dda6f4965b0690b1ccdf6d698"
      ],
      "layout": "IPY_MODEL_e99da6035d61497bb9f4a3a05ee712e0"
     }
    },
    "b5a4784195cb4c778c98d3b1c6c38a09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e99da6035d61497bb9f4a3a05ee712e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f17670119ae54e4897d09c7158582213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6131881749f46a9bc637e46a92062e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
